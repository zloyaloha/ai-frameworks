# ai-frameworks

### Классификация

Базовые модели зачастую страдают от того, что классы в задаче несбалансированны: для многих моделей F1 метрика второго класса сильно просаживается. Безооговорочно лучшей моделью оказалось решающее дерево, поскольку по сумме метрик оно выдало наилучший результат. Кроме того, она выдала наилучший результат по метрике F1 для второго класса, что является ключевым в задаче. Если нужно быстрое бизнес решение с приемлимыми метриками, я бы использовал градиентный бустинг, который даже при отстутствии тюнинга выдал приличные результаты.

|                            | ROC_AUC | F1 (1 класс) | F1 (2 класс) |
|----------------------------|---------|--------------|--------------|
| Baseline KNN               | 0.4674  | 0.81         | 0.06         |
| Improved KNN               | 0.8545  | 0.86         | 0.67         |
| My KNN                     | 0.8545  | 0.86         | 0.67         |
| Baseline Linear Classifier | 0.6118  | 0.86         | 0.00         |
| Linear Classifier          | 0.8513  | 0.88         | 0.62         |
| My Linear Classifier       | 0.8542  | 0.89         | 0.71         |
| Baseline Decision Tree     | 0.7447  | 0.86         | 0.61         |
| Decision Tree              | 0.8611  | 0.89         | 0.73         |
| My Decision Tree           | 0.8781  | 0.88         | 0.62         |
| Baseline Random Forest     | 0.8398  | 0.85         | 0.39         |
| Random Forest              | 0.8314  | 0.88         | 0.71         |
| My Random Forest           | 0.8515  | 0.88         | 0.59         |
| Baseline Gradient Boosting | 0.8380  | 0.88         | 0.65         |
| Gradient Boosting          | 0.8497  | 0.88         | 0.67         |
| My Gradient Boosting       | 0.8677  | 0.89         | 0.63         |

### Регрессия

По метрике $R^2$ лидирует Linear Regression (0.645), совсем немного обгоняя Gradient Boosting (0.640) и Random Forest (0.641). По метрике MAE выигрывает Gradient Boosting (850100) и Random Forest (851915), что говорит о том, что в среднем он ошибается меньше, хотя линейная регрессия лучше объясняет общую дисперсию данных.

Линейная регрессия показала себя неожиданно хорошо. Это может указывать на то, что зависимость в данных имеет преимущественно линейный характер, либо данных недостаточно для раскрытия потенциала сложных ансамблей.

KNN показал худшие результаты ($R^2 < 0.48$). Для задач регрессии на данных высокой размерности этот алгоритм часто неэффективен.

Разница между Base моделями и настроенными огромна. Например, для базовой линейной регрессии имеем $R^2$ 0.324, а для настроенной — 0.644.

Лучше всего при отсутствии тюнинга показал себя градиентный бустинг, который я бы рекомендовал использовать при нежелании тратить время на тюнинг.

|                        | MAE         | R2    |
|------------------------|-------------|-------|
| Base KNN               | 1173197.566 | 0.399 |
| KNN                    | 1069096.869 | 0.492 |
| My KNN                 | 1069096.869 | 0.492 |
| Base Linear Regression | 1381895.059 | 0.324 |
| Linear Regression      | 874617.127  | 0.645 |
| My Linear Regression   | 892750.102  | 0.622 |
| Base Decision Tree     | 1220967.395 | 0.322 |
| Decision Tree          | 865388.517  | 0.635 |
| My Decision Tree       | 870330.527  | 0.632 |
| Base Random Forest     | 973296.880  | 0.604 |
| Random Forest          | 851915.502  | 0.641 |
| My Random Forest       | 1104519.680 | 0.446 |
| Base Gradient Boosting | 963131.492  | 0.604 |
| Gradient Boosting      | 850100.263  | 0.640 |
| My gradient boosting   | 915417.103  | 0.570 |


### Вывод
Для Регрессии: лучшими моделями оказались градиентный бустинг или линейную регрессию.

Для Классификации: Для классификации я бы рекомендовал использовать дерево решений.

Собственные реализации моделей показали близкое качество к библиотечным версиям. Этот анализ демонстрирует, как важно учитывать структуру данных, их распределение, наличие выбросов и дисбаланс классов при выборе подходящего алгоритма. Не существует одной универсальной модели, подходящей для обеих задач, для обоих датасетов.